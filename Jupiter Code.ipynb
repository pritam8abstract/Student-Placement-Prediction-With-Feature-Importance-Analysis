{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19a20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b58512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Load Data#\n",
    "\n",
    "train_features_df = pd.read_csv('Train_Features.csv')\n",
    "train_target_df = pd.read_csv('Train_Target.csv')\n",
    "test_features_df = pd.read_csv('Test_Features.csv')\n",
    "sample_submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a31215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (300, 19)\n",
      "Training target shape: (300, 2)\n",
      "Test features shape: (91, 19)\n",
      "Sample submission shape: (91, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the datasets\n",
    "print(\"Training features shape:\", train_features_df.shape)\n",
    "print(\"Training target shape:\", train_target_df.shape)\n",
    "print(\"Test features shape:\", test_features_df.shape)\n",
    "print(\"Sample submission shape:\", sample_submission_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c98f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training features with target\n",
    "train_data = pd.merge(train_features_df, train_target_df, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3027eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of training data:\n",
      "   ID Gender  Percent_SSC Board_SSC  Percent_HSC Board_HSC Stream_HSC  \\\n",
      "0   1      M         56.0      ICSE         58.0       ISC   Commerce   \n",
      "1   2      M         41.0    Others         51.0    Others    Science   \n",
      "2   3      F         53.0    Others         40.0    Others       Arts   \n",
      "3   4      M         59.0    Others         58.0    Others   Commerce   \n",
      "4   5      F         61.5    Others         65.4      CBSE       Arts   \n",
      "\n",
      "   Percent_Degree          Course_Degree  Experience_Yrs Entrance_Test  \\\n",
      "0           67.00             Management               0           NaN   \n",
      "1           61.00  Computer Applications               1           MAT   \n",
      "2           54.00                   Arts               1           MAT   \n",
      "3           59.00             Management               0         G-MAT   \n",
      "4           67.93             Management               0           MAT   \n",
      "\n",
      "   S-TEST  Percentile_ET  S-TEST*SCORE  Percent_MBA   Specialization_MBA  \\\n",
      "0       0            0.0           0.0        65.28  Marketing & Finance   \n",
      "1       1           86.0          86.0        62.48  Marketing & Finance   \n",
      "2       1           65.0          65.0        56.11       Marketing & HR   \n",
      "3       1            0.0           0.0        59.81       Marketing & HR   \n",
      "4       1           61.0          61.0        64.27  Marketing & Finance   \n",
      "\n",
      "   Marks_Communication  Marks_Projectwork  Marks_BOCA  Placement  \n",
      "0                   62                 77          77          1  \n",
      "1                   59                 72          75          0  \n",
      "2                   54                 66          75          1  \n",
      "3                   53                 66          78          0  \n",
      "4                   69                 69          61          0  \n"
     ]
    }
   ],
   "source": [
    "# Check first few rows\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2f9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "ID                       int64\n",
      "Gender                  object\n",
      "Percent_SSC            float64\n",
      "Board_SSC               object\n",
      "Percent_HSC            float64\n",
      "Board_HSC               object\n",
      "Stream_HSC              object\n",
      "Percent_Degree         float64\n",
      "Course_Degree           object\n",
      "Experience_Yrs           int64\n",
      "Entrance_Test           object\n",
      "S-TEST                   int64\n",
      "Percentile_ET          float64\n",
      "S-TEST*SCORE           float64\n",
      "Percent_MBA            float64\n",
      "Specialization_MBA      object\n",
      "Marks_Communication      int64\n",
      "Marks_Projectwork        int64\n",
      "Marks_BOCA               int64\n",
      "Placement                int64\n",
      "dtype: object\n",
      "\n",
      "Missing values in training data:\n",
      "ID                      0\n",
      "Gender                  0\n",
      "Percent_SSC             0\n",
      "Board_SSC               0\n",
      "Percent_HSC             0\n",
      "Board_HSC               0\n",
      "Stream_HSC              0\n",
      "Percent_Degree          0\n",
      "Course_Degree           0\n",
      "Experience_Yrs          0\n",
      "Entrance_Test          53\n",
      "S-TEST                  0\n",
      "Percentile_ET           0\n",
      "S-TEST*SCORE            0\n",
      "Percent_MBA             0\n",
      "Specialization_MBA      0\n",
      "Marks_Communication     0\n",
      "Marks_Projectwork       0\n",
      "Marks_BOCA              0\n",
      "Placement               0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "ID                      0\n",
      "Gender                  0\n",
      "Percent_SSC             0\n",
      "Board_SSC               0\n",
      "Percent_HSC             0\n",
      "Board_HSC               0\n",
      "Stream_HSC              0\n",
      "Percent_Degree          0\n",
      "Course_Degree           0\n",
      "Experience_Yrs          0\n",
      "Entrance_Test          14\n",
      "S-TEST                  0\n",
      "Percentile_ET           0\n",
      "S-TEST*SCORE            0\n",
      "Percent_MBA             0\n",
      "Specialization_MBA      0\n",
      "Marks_Communication     0\n",
      "Marks_Projectwork       0\n",
      "Marks_BOCA              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "print(\"\\nData types:\")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_features_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c422cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics of numerical columns:\n",
      "               ID  Percent_SSC  Percent_HSC  Percent_Degree  Experience_Yrs  \\\n",
      "count  300.000000   300.000000   300.000000      300.000000      300.000000   \n",
      "mean   150.500000    64.472933    63.631667       63.228433        0.506667   \n",
      "std     86.746758    11.183569    11.526602        9.172405        0.686678   \n",
      "min      1.000000    37.000000    40.000000       35.000000        0.000000   \n",
      "25%     75.750000    56.000000    54.000000       58.000000        0.000000   \n",
      "50%    150.500000    64.250000    63.000000       63.845000        0.000000   \n",
      "75%    225.250000    73.820000    72.250000       69.000000        1.000000   \n",
      "max    300.000000    87.200000    94.700000       88.800000        3.000000   \n",
      "\n",
      "           S-TEST  Percentile_ET  S-TEST*SCORE  Percent_MBA  \\\n",
      "count  300.000000     300.000000    300.000000   300.000000   \n",
      "mean     0.823333      54.598300     54.598300    61.655733   \n",
      "std      0.382024      31.120892     31.120892     5.840537   \n",
      "min      0.000000       0.000000      0.000000    50.830000   \n",
      "25%      1.000000      42.815000     42.815000    57.082500   \n",
      "50%      1.000000      62.000000     62.000000    61.115000   \n",
      "75%      1.000000      78.000000     78.000000    65.807500   \n",
      "max      1.000000      98.690000     98.690000    77.890000   \n",
      "\n",
      "       Marks_Communication  Marks_Projectwork  Marks_BOCA   Placement  \n",
      "count           300.000000         300.000000  300.000000  300.000000  \n",
      "mean             60.430000          68.416667   64.683333    0.203333  \n",
      "std               8.790298           7.006189    9.504957    0.403151  \n",
      "min              50.000000          50.000000   50.000000    0.000000  \n",
      "25%              53.000000          64.000000   57.000000    0.000000  \n",
      "50%              58.000000          69.000000   64.000000    0.000000  \n",
      "75%              67.000000          74.000000   73.000000    0.000000  \n",
      "max              88.000000          87.000000   96.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(\"\\nBasic statistics of numerical columns:\")\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457c5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "Placement\n",
      "0    239\n",
      "1     61\n",
      "Name: count, dtype: int64\n",
      "Placement\n",
      "0    79.666667\n",
      "1    20.333333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the target variable distribution\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(train_data['Placement'].value_counts())\n",
    "print(train_data['Placement'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44e0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Placement', data=train_data)\n",
    "plt.title('Placement Distribution')\n",
    "plt.xlabel('Placement (0: Placed, 1: Not Placed)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('placement_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2894faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if 'ID' in numerical_cols:\n",
    "    numerical_cols.remove('ID')\n",
    "if 'Placement' in numerical_cols:\n",
    "    numerical_cols.remove('Placement')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = train_data[numerical_cols + ['Placement']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d0cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in Entrance_Test column:\n",
      "Entrance_Test\n",
      "MAT      199\n",
      "K-MAT     20\n",
      "CAT       18\n",
      "PGCET      6\n",
      "GCET       2\n",
      "G-MAT      1\n",
      "G-SAT      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values in Entrance_Test column\n",
    "# Check unique values in the column\n",
    "print(\"\\nUnique values in Entrance_Test column:\")\n",
    "print(train_data['Entrance_Test'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6b2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentile_ET statistics by Entrance_Test:\n",
      "               count       mean        std    min      25%   50%     75%  \\\n",
      "Entrance_Test                                                              \n",
      "CAT             18.0  59.299444  20.110281  13.00  53.8475  64.0  72.250   \n",
      "G-MAT            1.0   0.000000        NaN   0.00   0.0000   0.0   0.000   \n",
      "G-SAT            1.0   0.000000        NaN   0.00   0.0000   0.0   0.000   \n",
      "GCET             2.0  45.000000   7.071068  40.00  42.5000  45.0  47.500   \n",
      "K-MAT           20.0  74.459000  20.605304  14.99  64.7500  77.6  89.575   \n",
      "MAT            199.0  68.336281  16.163695  22.95  57.1000  67.0  80.200   \n",
      "PGCET            6.0  22.333333  36.423436   0.00   0.0000   0.0  36.750   \n",
      "\n",
      "                 max  \n",
      "Entrance_Test         \n",
      "CAT            80.00  \n",
      "G-MAT           0.00  \n",
      "G-SAT           0.00  \n",
      "GCET           50.00  \n",
      "K-MAT          98.69  \n",
      "MAT            98.00  \n",
      "PGCET          85.00  \n"
     ]
    }
   ],
   "source": [
    "# Let's look at Percentile_ET distribution based on Entrance_Test\n",
    "print(\"\\nPercentile_ET statistics by Entrance_Test:\")\n",
    "print(train_data.groupby('Entrance_Test')['Percentile_ET'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737e9212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in Entrance_Test column:\n",
      "Entrance_Test\n",
      "MAT      199\n",
      "K-MAT     20\n",
      "CAT       18\n",
      "PGCET      6\n",
      "GCET       2\n",
      "G-MAT      1\n",
      "G-SAT      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentile_ET statistics by Entrance_Test:\n",
      "               count       mean        std    min      25%   50%     75%  \\\n",
      "Entrance_Test                                                              \n",
      "CAT             18.0  59.299444  20.110281  13.00  53.8475  64.0  72.250   \n",
      "G-MAT            1.0   0.000000        NaN   0.00   0.0000   0.0   0.000   \n",
      "G-SAT            1.0   0.000000        NaN   0.00   0.0000   0.0   0.000   \n",
      "GCET             2.0  45.000000   7.071068  40.00  42.5000  45.0  47.500   \n",
      "K-MAT           20.0  74.459000  20.605304  14.99  64.7500  77.6  89.575   \n",
      "MAT            199.0  68.336281  16.163695  22.95  57.1000  67.0  80.200   \n",
      "PGCET            6.0  22.333333  36.423436   0.00   0.0000   0.0  36.750   \n",
      "\n",
      "                 max  \n",
      "Entrance_Test         \n",
      "CAT            80.00  \n",
      "G-MAT           0.00  \n",
      "G-SAT           0.00  \n",
      "GCET           50.00  \n",
      "K-MAT          98.69  \n",
      "MAT            98.00  \n",
      "PGCET          85.00  \n",
      "\n",
      "Numerical columns: ['Percent_SSC', 'Percent_HSC', 'Percent_Degree', 'Experience_Yrs', 'S-TEST', 'Percentile_ET', 'S-TEST*SCORE', 'Percent_MBA', 'Marks_Communication', 'Marks_Projectwork', 'Marks_BOCA']\n",
      "Categorical columns: ['Gender', 'Board_SSC', 'Board_HSC', 'Stream_HSC', 'Course_Degree', 'Entrance_Test', 'Specialization_MBA']\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values in Entrance_Test column\n",
    "# Check unique values in the column\n",
    "print(\"\\nUnique values in Entrance_Test column:\")\n",
    "print(train_data['Entrance_Test'].value_counts())\n",
    "\n",
    "# Let's look at Percentile_ET distribution based on Entrance_Test\n",
    "print(\"\\nPercentile_ET statistics by Entrance_Test:\")\n",
    "print(train_data.groupby('Entrance_Test')['Percentile_ET'].describe())\n",
    "\n",
    "# Strategy for handling missing values:\n",
    "# 1. For numerical columns: impute with median\n",
    "# 2. For categorical columns: impute with most frequent value\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'ID' in categorical_cols:\n",
    "    categorical_cols.remove('ID')\n",
    "\n",
    "print(\"\\nNumerical columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Prepare preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Prepare preprocessing for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d906d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (240, 18)\n",
      "Validation set shape: (60, 18)\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train and validation sets\n",
    "X = train_data.drop(['ID', 'Placement'], axis=1)\n",
    "y = train_data['Placement']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"\\nTraining set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ddcd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in processed training data:\n",
      "43\n",
      "\n",
      "Missing values in processed validation data:\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in processed training data:\")\n",
    "print(X_train.isnull().sum().sum())\n",
    "print(\"\\nMissing values in processed validation data:\")\n",
    "print(X_val.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f1d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in processed training data:\n",
      "0\n",
      "\n",
      "Missing values in processed validation data:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessor to check imputation\n",
    "X_train_processed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    # Note: Column names will be lost after transformation\n",
    ")\n",
    "X_val_processed = pd.DataFrame(\n",
    "    preprocessor.transform(X_val),\n",
    "    # Note: Column names will be lost after transformation\n",
    ")\n",
    "\n",
    "print(\"\\nMissing values in processed training data:\")\n",
    "print(X_train_processed.isnull().sum().sum())\n",
    "print(\"\\nMissing values in processed validation data:\")\n",
    "print(X_val_processed.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for class imbalance\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6005de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to try\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store model performance\n",
    "model_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d503b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Training RandomForest...\n",
      "RandomForest - Accuracy: 0.8000, F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        48\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.40      0.50      0.44        60\n",
      "weighted avg       0.64      0.80      0.71        60\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training GradientBoosting...\n",
      "GradientBoosting - Accuracy: 0.7333, F1 Score: 0.1111\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84        48\n",
      "           1       0.17      0.08      0.11        12\n",
      "\n",
      "    accuracy                           0.73        60\n",
      "   macro avg       0.48      0.49      0.48        60\n",
      "weighted avg       0.67      0.73      0.70        60\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training LogisticRegression...\n",
      "LogisticRegression - Accuracy: 0.7500, F1 Score: 0.2105\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        48\n",
      "           1       0.29      0.17      0.21        12\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.55      0.53      0.53        60\n",
      "weighted avg       0.71      0.75      0.72        60\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training XGBoost...\n",
      "XGBoost - Accuracy: 0.7667, F1 Score: 0.1250\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87        48\n",
      "           1       0.25      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.53      0.51      0.50        60\n",
      "weighted avg       0.69      0.77      0.72        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'-'*50}\\nTraining {name}...\")\n",
    "    \n",
    "    # Create a pipeline with preprocessing and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    model_scores[name] = (accuracy, f1)\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(f'confusion_matrix_{name}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3051775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: LogisticRegression with F1 Score of 0.2105\n",
      "\n",
      "--------------------------------------------------\n",
      "Fine-tuning LogisticRegression...\n",
      "Best parameters: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best cross-validation F1 score: 0.2096\n"
     ]
    }
   ],
   "source": [
    "# Select the best model based on F1 score\n",
    "best_model_name = max(model_scores, key=lambda x: model_scores[x][1])\n",
    "best_f1 = model_scores[best_model_name][1]\n",
    "print(f\"\\nBest model: {best_model_name} with F1 Score of {best_f1:.4f}\")\n",
    "\n",
    "# Fine-tune the best model\n",
    "print(f\"\\n{'-'*50}\\nFine-tuning {best_model_name}...\")\n",
    "\n",
    "if best_model_name == 'RandomForest':\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "elif best_model_name == 'GradientBoosting':\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    }\n",
    "elif best_model_name == 'LogisticRegression':\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'classifier__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "else:  # XGBoost\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "# Create the base pipeline with the best model\n",
    "best_model = models[best_model_name]\n",
    "best_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(\n",
    "    best_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dfaeab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned LogisticRegression - Accuracy: 0.7333, F1 Score: 0.2000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        48\n",
      "           1       0.25      0.17      0.20        12\n",
      "\n",
      "    accuracy                           0.73        60\n",
      "   macro avg       0.53      0.52      0.52        60\n",
      "weighted avg       0.70      0.73      0.71        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tuned model on validation set\n",
    "tuned_model = grid_search.best_estimator_\n",
    "y_pred_tuned = tuned_model.predict(X_val)\n",
    "tuned_f1 = f1_score(y_val, y_pred_tuned)\n",
    "tuned_accuracy = accuracy_score(y_val, y_pred_tuned)\n",
    "\n",
    "print(f\"\\nTuned {best_model_name} - Accuracy: {tuned_accuracy:.4f}, F1 Score: {tuned_f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be536b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model on complete training dataset...\n",
      "\n",
      "Making predictions on test data...\n",
      "Submission file created: final_submission.csv\n",
      "\n",
      "Summary of model performance:\n",
      "RandomForest         - Accuracy: 0.8000, F1 Score: 0.0000\n",
      "GradientBoosting     - Accuracy: 0.7333, F1 Score: 0.1111\n",
      "LogisticRegression   - Accuracy: 0.7500, F1 Score: 0.2105\n",
      "XGBoost              - Accuracy: 0.7667, F1 Score: 0.1250\n",
      "\n",
      "Tuned LogisticRegression   - Accuracy: 0.7333, F1 Score: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis (if the model supports it)\n",
    "if best_model_name in ['RandomForest', 'GradientBoosting', 'XGBoost']:\n",
    "    # Get feature names after preprocessing\n",
    "    preprocessor.fit(X_train)\n",
    "    cat_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
    "    feature_names = numerical_cols + list(cat_features)\n",
    "    \n",
    "    # Get feature importances\n",
    "    if best_model_name == 'XGBoost':\n",
    "        importances = tuned_model.named_steps['classifier'].feature_importances_\n",
    "    else:\n",
    "        importances = tuned_model.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names[:len(importances)],  # Ensure matching length\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nTop 10 important features:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "# Final model training on complete training data\n",
    "print(\"\\nTraining final model on complete training dataset...\")\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Make predictions on test data\n",
    "print(\"\\nMaking predictions on test data...\")\n",
    "test_predictions = final_model.predict(test_features_df.drop('ID', axis=1))\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_features_df['ID'],\n",
    "    'Placement': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "print(\"Submission file created: final_submission.csv\")\n",
    "\n",
    "# Summary of model performance\n",
    "print(\"\\nSummary of model performance:\")\n",
    "for name, (acc, f1) in model_scores.items():\n",
    "    print(f\"{name:20} - Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "print(f\"\\nTuned {best_model_name:20} - Accuracy: {tuned_accuracy:.4f}, F1 Score: {tuned_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d7adc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final submission file:\n",
      "   ID  Placement\n",
      "0   1          0\n",
      "1   2          0\n",
      "2   3          0\n",
      "3   4          0\n",
      "4   5          1\n"
     ]
    }
   ],
   "source": [
    "# View the final submission file\n",
    "print(\"\\nFinal submission file:\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
